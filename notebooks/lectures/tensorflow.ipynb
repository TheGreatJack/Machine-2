{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is a powerful open source software library for numerical computation,\n",
    "particularly well suited and fine-tuned for large-scale Machine Learning. Its basic\n",
    "principle is simple: you first define in Python a graph of computations to perform,\n",
    "and then TensorFlow takes that graph and runs it efficiently using optimized C++ code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some installation notes\n",
    "* For GPU support, you need to install tensorflow-gpu instead of tensorflow.\n",
    "* Use `conda` instead of `pip` (See [this](https://towardsdatascience.com/stop-installing-tensorflow-using-pip-for-performance-sake-5854f9d9eb0c) benchmark)\n",
    "* Use python 3.6 (for the moment, avoid python 3.7)\n",
    "* Check tensorflow version\n",
    "* Source installation, not so friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "* The `variable`'s have a fixed size, they contain the parameters of a model, which can then be saved or restored.\n",
    "\n",
    "* The `variable`'s can have a constant value, but they are usually initialized with some random or determined value, and their content varies during the optimization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'x:0' shape=() dtype=int32_ref>\n",
      "<tf.Variable 'y:0' shape=() dtype=int32_ref>\n",
      "Tensor(\"add_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2\n",
    "print(x)\n",
    "print(y)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"tmp\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.11.0 at http://biocomp06:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook trick\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifecycle of a Node Value\n",
    "When you evaluate a node, TensorFlow automatically determines the set of nodes\n",
    "that it depends on and it evaluates these nodes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n",
      "CPU times: user 10.6 ms, sys: 0 ns, total: 10.6 ms\n",
      "Wall time: 8.24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n",
      "CPU times: user 6.22 ms, sys: 603 Âµs, total: 6.83 ms\n",
      "Wall time: 5.66 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "$$\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n $$\n",
    "where\n",
    "* $\\hat{y}$ is the predicted value\n",
    "* $n$ is the number of features\n",
    "* $x_i$ is the i$^\\text{th}$ feature\n",
    "* $x_j$ is the j$^\\text{th}$ model parameter\n",
    "\n",
    "$$\\hat{y} = h_\\theta(x) = \\theta^T \\cdot \\textbf{x} $$\n",
    "#### Optimize\n",
    "**The Normal Equation** \n",
    "$$\\hat\\theta = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = 100\n",
    "\n",
    "X = 2 * np.random.rand(m, 1)\n",
    "Y = 4 + 3 * X + np.random.randn(m, 1)\n",
    "\n",
    "plt.scatter(X,Y)\n",
    "\n",
    "X_b = np.c_[np.ones((100, 1)), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(X_b, dtype=tf.float32, name='X')\n",
    "y = tf.constant(Y, dtype=tf.float32, name='y')\n",
    "xt = tf.transpose(x)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(xt, x)), xt), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", shape=(100, 2), dtype=float32)\n",
      "Tensor(\"MatMul_2:0\", shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.158507],\n",
       "       [2.948627]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like Numpy, more code, great GPU support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(1,) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.Variable(initial_value=tf.random_normal([1]), name=\"x\", dtype=tf.float32)\n",
    "y = tf.Variable(initial_value=tf.random_normal([1]), name=\"y\", dtype=tf.float32)\n",
    "f = x**2+y**2\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = tf.gradients(f, x)\n",
    "dy = tf.gradients(f, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " f(5,2) = 29\n",
      "dx(5,2) = 10\n",
      "dy(5,2) = 4\n"
     ]
    }
   ],
   "source": [
    "val_x, val_y = 5, 2\n",
    "with tf.Session() as sess:\n",
    "    val_f, val_dx, val_dy = sess.run([f, dx, dy], feed_dict={x: [val_x], y:[val_y]})\n",
    "print(\" f(%d,%d) = %d\"%(val_x, val_y, val_f))\n",
    "print(\"dx(%d,%d) = %d\"%(val_x, val_y, val_dx[0]))\n",
    "print(\"dy(%d,%d) = %d\"%(val_x, val_y, val_dy[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sympy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b84266c7e9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sympy'"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, diff, evalf\n",
    "\n",
    "x, y = symbols('x y')\n",
    "f = x**2 + y**2\n",
    "dx = diff(f, x)\n",
    "dy = diff(f, y)\n",
    "print(f,'\\t', dx,'\\t', dy)\n",
    "print(\" f(%d,%d) = %d\"%(val_x, val_y, f.evalf(subs={x:val_x, y:val_y})))\n",
    "print(\"dx(%d,%d) = %d\"%(val_x, val_y, dx.evalf(subs={x:val_x, y:val_y})))\n",
    "print(\"dy(%d,%d) = %d\"%(val_x, val_y, dy.evalf(subs={x:val_x, y:val_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So TensorFlow computes the gradients for you. But it gets even easier: it also provides\n",
    "a number of optimizers out of the box, including a Gradient Descent optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding Data to the Training Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "* The `placeholder`'s can be matrices (tensors) with a fixed number of columns, but variable rows, in order to evaluate expressions with different datasets.\n",
    "\n",
    "* The `placeholder`'s do not have initial values, and you have to feed them directly with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "    \n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save\n",
    "```python\n",
    "[...]\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "[...]\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0: # checkpoint every 100 epochs\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "    \n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore\n",
    "```python\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    [...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default a Saver saves and restores all variables under their own name, but if you\n",
    "need more control, you can specify which variables to save or restore\n",
    "```python\n",
    "saver = tf.train.Saver({\"weights\": theta})```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Example](TF-01.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Validation-set:\t5000\n",
      "- Test-set:\t\t10000\n"
     ]
    }
   ],
   "source": [
    "from Utils.mnist import MNIST\n",
    "data = MNIST(data_dir=\"data/MNIST\")\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(data.num_train))\n",
    "print(\"- Validation-set:\\t{}\".format(data.num_val))\n",
    "print(\"- Test-set:\\t\\t{}\".format(data.num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               100500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 341,610\n",
      "Trainable params: 341,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model_A():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='tanh', input_dim=784))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dense(500, activation='tanh'))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dense(200, activation='tanh'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.reset_states()\n",
    "    return model\n",
    "\n",
    "model = get_model_A()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "10000/10000 [==============================] - 2s 153us/step - loss: 0.4681 - acc: 0.8532 - val_loss: 0.2667 - val_acc: 0.9170\n",
      "Epoch 2/40\n",
      "10000/10000 [==============================] - 1s 90us/step - loss: 0.2527 - acc: 0.9215 - val_loss: 0.1983 - val_acc: 0.9382\n",
      "Epoch 3/40\n",
      "10000/10000 [==============================] - 1s 101us/step - loss: 0.2032 - acc: 0.9361 - val_loss: 0.1564 - val_acc: 0.9517\n",
      "Epoch 4/40\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 0.1576 - acc: 0.9492 - val_loss: 0.1201 - val_acc: 0.9594\n",
      "Epoch 5/40\n",
      "10000/10000 [==============================] - 1s 95us/step - loss: 0.1212 - acc: 0.9602 - val_loss: 0.0885 - val_acc: 0.9710\n",
      "Epoch 6/40\n",
      "10000/10000 [==============================] - 1s 95us/step - loss: 0.0989 - acc: 0.9685 - val_loss: 0.0558 - val_acc: 0.9852\n",
      "Epoch 7/40\n",
      "10000/10000 [==============================] - 1s 107us/step - loss: 0.0655 - acc: 0.9800 - val_loss: 0.0795 - val_acc: 0.9717\n",
      "Epoch 8/40\n",
      "10000/10000 [==============================] - 1s 109us/step - loss: 0.0636 - acc: 0.9781 - val_loss: 0.0546 - val_acc: 0.9830\n",
      "Epoch 9/40\n",
      "10000/10000 [==============================] - 1s 103us/step - loss: 0.0635 - acc: 0.9794 - val_loss: 0.0655 - val_acc: 0.9779\n",
      "Epoch 10/40\n",
      "10000/10000 [==============================] - 1s 97us/step - loss: 0.0456 - acc: 0.9851 - val_loss: 0.0417 - val_acc: 0.9861\n",
      "Epoch 11/40\n",
      "10000/10000 [==============================] - 1s 97us/step - loss: 0.0351 - acc: 0.9883 - val_loss: 0.0212 - val_acc: 0.9943\n",
      "Epoch 12/40\n",
      "10000/10000 [==============================] - 1s 97us/step - loss: 0.0262 - acc: 0.9920 - val_loss: 0.0198 - val_acc: 0.9939\n",
      "Epoch 13/40\n",
      "10000/10000 [==============================] - 1s 107us/step - loss: 0.0329 - acc: 0.9889 - val_loss: 0.0200 - val_acc: 0.9939\n",
      "Epoch 14/40\n",
      "10000/10000 [==============================] - 1s 95us/step - loss: 0.0340 - acc: 0.9886 - val_loss: 0.0171 - val_acc: 0.9950\n",
      "Epoch 15/40\n",
      "10000/10000 [==============================] - 1s 95us/step - loss: 0.0295 - acc: 0.9911 - val_loss: 0.0361 - val_acc: 0.9869\n",
      "Epoch 16/40\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 0.0395 - acc: 0.9877 - val_loss: 0.0226 - val_acc: 0.9925\n",
      "Epoch 17/40\n",
      "10000/10000 [==============================] - 1s 103us/step - loss: 0.0162 - acc: 0.9955 - val_loss: 0.0066 - val_acc: 0.9987\n",
      "Epoch 18/40\n",
      "10000/10000 [==============================] - 1s 97us/step - loss: 0.0144 - acc: 0.9959 - val_loss: 0.0235 - val_acc: 0.9928\n",
      "Epoch 19/40\n",
      "10000/10000 [==============================] - 1s 101us/step - loss: 0.0304 - acc: 0.9911 - val_loss: 0.0182 - val_acc: 0.9944\n",
      "Epoch 20/40\n",
      "10000/10000 [==============================] - 1s 109us/step - loss: 0.0247 - acc: 0.9913 - val_loss: 0.0109 - val_acc: 0.9969\n",
      "Epoch 21/40\n",
      "10000/10000 [==============================] - 1s 101us/step - loss: 0.0139 - acc: 0.9954 - val_loss: 0.0170 - val_acc: 0.9947\n",
      "Epoch 22/40\n",
      "10000/10000 [==============================] - 1s 104us/step - loss: 0.0188 - acc: 0.9937 - val_loss: 0.0316 - val_acc: 0.9892\n",
      "Epoch 23/40\n",
      "10000/10000 [==============================] - 1s 104us/step - loss: 0.0299 - acc: 0.9906 - val_loss: 0.0206 - val_acc: 0.9945\n",
      "Epoch 24/40\n",
      "10000/10000 [==============================] - 1s 110us/step - loss: 0.0097 - acc: 0.9965 - val_loss: 0.0022 - val_acc: 0.9995\n",
      "Epoch 25/40\n",
      "10000/10000 [==============================] - 1s 102us/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0012 - val_acc: 0.9999\n",
      "Epoch 26/40\n",
      "10000/10000 [==============================] - 1s 104us/step - loss: 8.1708e-04 - acc: 1.0000 - val_loss: 4.6487e-04 - val_acc: 1.0000\n",
      "Epoch 27/40\n",
      "10000/10000 [==============================] - 1s 107us/step - loss: 4.1808e-04 - acc: 1.0000 - val_loss: 3.3141e-04 - val_acc: 1.0000\n",
      "Epoch 28/40\n",
      "10000/10000 [==============================] - 1s 103us/step - loss: 3.1851e-04 - acc: 1.0000 - val_loss: 2.7793e-04 - val_acc: 1.0000\n",
      "Epoch 29/40\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 2.7031e-04 - acc: 1.0000 - val_loss: 2.4071e-04 - val_acc: 1.0000\n",
      "Epoch 30/40\n",
      "10000/10000 [==============================] - 1s 113us/step - loss: 2.3541e-04 - acc: 1.0000 - val_loss: 2.1203e-04 - val_acc: 1.0000\n",
      "Epoch 31/40\n",
      "10000/10000 [==============================] - 1s 102us/step - loss: 2.0790e-04 - acc: 1.0000 - val_loss: 1.8907e-04 - val_acc: 1.0000\n",
      "Epoch 32/40\n",
      "10000/10000 [==============================] - 1s 107us/step - loss: 1.8553e-04 - acc: 1.0000 - val_loss: 1.6963e-04 - val_acc: 1.0000\n",
      "Epoch 33/40\n",
      "10000/10000 [==============================] - 1s 97us/step - loss: 1.6684e-04 - acc: 1.0000 - val_loss: 1.5315e-04 - val_acc: 1.0000\n",
      "Epoch 34/40\n",
      "10000/10000 [==============================] - 1s 98us/step - loss: 1.5049e-04 - acc: 1.0000 - val_loss: 1.3881e-04 - val_acc: 1.0000\n",
      "Epoch 35/40\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 1.3645e-04 - acc: 1.0000 - val_loss: 1.2619e-04 - val_acc: 1.0000\n",
      "Epoch 36/40\n",
      "10000/10000 [==============================] - 1s 97us/step - loss: 1.2417e-04 - acc: 1.0000 - val_loss: 1.1492e-04 - val_acc: 1.0000\n",
      "Epoch 37/40\n",
      "10000/10000 [==============================] - 1s 102us/step - loss: 1.1334e-04 - acc: 1.0000 - val_loss: 1.0514e-04 - val_acc: 1.0000\n",
      "Epoch 38/40\n",
      "10000/10000 [==============================] - 1s 99us/step - loss: 1.0356e-04 - acc: 1.0000 - val_loss: 9.6191e-05 - val_acc: 1.0000\n",
      "Epoch 39/40\n",
      "10000/10000 [==============================] - 1s 98us/step - loss: 9.4805e-05 - acc: 1.0000 - val_loss: 8.8309e-05 - val_acc: 1.0000\n",
      "Epoch 40/40\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 8.7005e-05 - acc: 1.0000 - val_loss: 8.0927e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f48b8057470>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data.x_test, data.y_test, epochs=40, batch_size=64, validation_data=(data.x_test, data.y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
